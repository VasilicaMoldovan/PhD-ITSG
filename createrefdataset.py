# -*- coding: utf-8 -*-
"""CreateRefDataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19s_MtC9DkbY8Amji8YMMkPivA5yRbD4f
"""

# Create needed structure for predicting software refactorings and their types, based on td data

import pandas as pd
import ast
from collections import Counter

from google.colab import drive
drive.mount('/content/gdrive')

df = pd.read_excel('/content/gdrive/MyDrive/maintainability/all_technical_debt_issues.xlsx')

df = df[df['project']=='jEdit']

columns_to_drop = ['project', 'key', 'rule', 'resolution', 'status', 'message',  'creationDate', 'updateDate', 'closeDate', 'tags']
df = df.drop(columns=columns_to_drop)

print(df)

df_ref = pd.read_excel('/content/gdrive/MyDrive/maintainability/Refs/JEditRefactorings.xlsx')

def transform_string(original_string):
    parts = original_string.rsplit('.', 1)
    transformed_parts = [part.replace('.', '/') for part in parts[:-1]] + [parts[-1]]
    return '.'.join(transformed_parts)

df_ref['Class'] = df_ref['Class'].apply(transform_string)
df_ref['Class'] = 'src/' + df_ref['Class']

df_ref['Class'] = df_ref['Class'].replace('\.', '/', regex=True)

df_ref['Class'] = 'src/' + df_ref['Class']
df_ref['Class'] = df_ref['Class'] + '.java'

print(df_ref)

df_ref = df_ref.drop(columns=['Refactoring Description'])

grouped_df = df_ref.groupby('Class').agg(lambda x: list(x)).reset_index()

# Rename the columns
grouped_df.columns = ['Class', 'Types']
print(grouped_df)

grouped_df = grouped_df.rename(columns={'Class': 'component'})
print(grouped_df)

merged_df = pd.merge(df, grouped_df, on='component')

merged_df = pd.merge(df, grouped_df, on='component', how='left')

# Fill NaN values in 'Value2' column with empty lists
merged_df['Types'].fillna(value=pd.Series([[]] * len(merged_df)), inplace=True)

print(merged_df)

excel_file_path = '/content/gdrive/MyDrive/maintainability/Refs/JEditRefactoringsAndTD.xlsx'
merged_df.to_excel(excel_file_path, index=False)

# Compress all issues to only one per component

df_refactorings = pd.read_excel('/content/gdrive/MyDrive/maintainability/Refs/TuxGuitarRefactoringsAndTD.xlsx')

def is_float(value):
    try:
        float(value)
        return True
    except ValueError:
        return False

def adjust_debt(debt):
    if debt == None or debt == 'n/a':
        return 0
    return debt

def adjust_excel(data):
    severities = {}
    types = {}
    debts = {}
    ref_types = {}
    severity = {'MINOR': 2,  'MAJOR': 3,  'INFO': 1, 'CRITICAL': 4,  'BLOCKER': 5}

    if not is_float(data.loc[0, 'severity']):
        frequencyClass = {}
        type = {'BUG': 2, 'VULNERABILITY': 3, 'CODE_SMELL': 1}

        for i in range(len(data)):
            if data.loc[i, 'component'] in frequencyClass.keys():
                if adjust_debt(data.loc[i, 'debt']) > 0:
                    frequencyClass[data.loc[i, 'component']] += 1
                    debts[data.loc[i, 'component']] += data.loc[i, 'debt']
                    severities[data.loc[i, 'component']] += severity[data.loc[i, 'severity']]
                    types[data.loc[i, 'component']] += type[data.loc[i, 'type']]
                    if data.loc[i, 'Types'] != [] and data.loc[i, 'Types'] != "[]":
                      ref_types[data.loc[i, 'component']] += ast.literal_eval(data.loc[i, 'Types'])
            else:
                if adjust_debt(data.loc[i, 'debt']) > 0:
                    frequencyClass[data.loc[i, 'component']] = 1
                    debts[data.loc[i, 'component']] = data.loc[i, 'debt']
                    severities[data.loc[i, 'component']] = severity[data.loc[i, 'severity']]
                    types[data.loc[i, 'component']] = type[data.loc[i, 'type']]
                    ref_types[data.loc[i, 'component']] = ast.literal_eval(data.loc[i, 'Types'])

        for key in frequencyClass:
            severities[key] /= frequencyClass[key]
            debts[key] /= frequencyClass[key]
            types[key] /= frequencyClass[key]

        components = frequencyClass.keys()
        newData = {"component": components, "severity": severities.values(), "debt": debts.values(), "type": types.values(), "RTypes": ref_types.values(),
                "FrequencyClass": frequencyClass.values()}
        df = pd.DataFrame(newData)
        return df
    else:
        newData = {"component": data['component'], "severity": data['severity'], "debt": data['debt'],
                   "type": data['type'], "RTypes": data['Types'],
                   "FrequencyClass": data['FrequencyClass']}
        df = pd.period_range.DataFrame(newData)
        return df

df_refactorings = adjust_excel(df_refactorings)

print(df_refactorings)

excel_file_path = '/content/gdrive/MyDrive/maintainability/Refs/TuxGuitarRefactoringsAndTDSingleInst.xlsx'
df_refactorings.to_excel(excel_file_path, index=False)

# Create new data. Data is not only one per component, but each component has as many instances as refactorings performed upon it

excel_file_path = '/content/gdrive/MyDrive/maintainability/Refs/TuxGuitarRefactoringsAndTD.xlsx'
df_refs_all = pd.read_excel(excel_file_path)

def prepare_for_explosion(data):
  for index, row in data.iterrows():
    if row['Types'][-1] != "]":
      last_comma_index = row['Types'].rfind(',')
      new_string = row['Types'][:last_comma_index]
      new_string += "]"
      df_refs_all.at[index, 'Types'] = new_string
      #if row['RTypes'][-1] != '\'':
      #  if row['RTypes'][-1] == ',':
      #    row['RTypes'] = row['RTypes'][:-1]
      #  row['RTypes'] += "'"
    df_refs_all.at[index, 'Types'] = ast.literal_eval(df_refs_all.at[index, 'Types'] )
  return data

df_refs_all = prepare_for_explosion(df_refs_all)

print(type(df_refs_all.loc[0, 'Types']))

df2 = df_refs_all.explode('Types').reset_index(drop=True)
print(df2)

df2['Types'] = df2['Types'].fillna("Empty_list")

print(df2)

excel_file_path = '/content/gdrive/MyDrive/maintainability/Refs/TuxGuitarRefactoringsAndTDRefAll.xlsx'
df2.to_excel(excel_file_path, index=False)

# Create dataset with single inst with the most predominant refactoring type or the least common one

excel_file_path = '/content/gdrive/MyDrive/maintainability/Refs/TuxGuitarRefactoringsAndTD.xlsx'
df = pd.read_excel(excel_file_path)

ref_assigned = {}

from os import minor
def find_equal_index(array):
  count  = 0
  for i in range(1, len(array)):
    if array[i - 1] == array[i]:
      count += 1
    else:
      break
  return count

def find_refactoring_general(ref_array):
  ref_type = None
  element_counts = Counter(ref_array)
  count = find_equal_index(list(element_counts.values()))
  most_common_elements = element_counts.most_common(count)

  if count == 0:
    return 'Empty_list'
  else:
    min_app = 100000
    index = 0
    for i in range(0, count):
      if most_common_elements[i][0] not in ref_assigned.keys():
        ref_assigned[most_common_elements[i][0]] = 1
        ref_type = most_common_elements[i][0]
        break

      if most_common_elements[i][0] in ref_assigned.keys():
        if min_app > ref_assigned[most_common_elements[i][0]]:
          min_app = ref_assigned[most_common_elements[i][0]]
          index = i

    if ref_type == None:
      ref_type = most_common_elements[index][0]

  return ref_type

def find_refactoring(ref_array):
  ref_type = None
  element_counts = Counter(ref_array)
  most_common_elements = element_counts.most_common(2)
  if len(most_common_elements) == 0:
    return 'Empty_list'

  if len(most_common_elements) == 2 and most_common_elements[0][1] == most_common_elements[1][1]:
    if most_common_elements[0] not in ref_assigned.keys():
      ref_assigned[most_common_elements[0]] = 1
      ref_type = most_common_elements[0]
    else:
      if len(most_common_elements) == 2:
        if most_common_elements[0] in ref_assigned.keys():
          if most_common_elements[1] not in ref_assigned.keys():
            ref_assigned[most_common_elements[1]] = 1
            ref_type = most_common_elements[1]
          else:
            if most_common_elements[0][1] >= most_common_elements[1][1]:
              ref_assigned[most_common_elements[1]] += 1
              ref_type = most_common_elements[1]
            else:
              ref_assigned[most_common_elements[0]] += 1
              ref_type = most_common_elements[0]
        else:
          ref_assigned[most_common_elements[0]] = 1
          ref_type = most_common_elements[0]
      else:
        if most_common_elements[0] not in ref_assigned.keys():
          ref_assigned[most_common_elements[0]] = 1
          ref_type = most_common_elements[0]
        else:
          ref_assigned[most_common_elements[0]] += 1
          ref_type = most_common_elements[0]
  else:
    ref_type = most_common_elements[0]
    if most_common_elements[0] not in ref_assigned.keys():
        ref_type = most_common_elements[0]
    else:
        ref_assigned[most_common_elements[0]] += 1

  return ref_type[0]

for index, row in df.iterrows():
  if df.at[index, 'Types'] != "[]":
    ref = find_refactoring_general(ast.literal_eval(df.at[index, 'Types']))
    df.at[index, 'Types'] = ref

excel_file_path = '/content/gdrive/MyDrive/maintainability/Refs/TuxGuitarRefactoringsAndTDOneRef.xlsx'
df.to_excel(excel_file_path, index=False)

# Apply the reduction method

excel_file_path = '/content/gdrive/MyDrive/maintainability/Refs/TuxGuitarRefactoringsAndTDOneRef.xlsx'
df = pd.read_excel(excel_file_path)

def adjust_excel_with_avg_mean(data):
    severities = {}
    types = {}
    debts = {}
    severity = {'MINOR': 2,  'MAJOR': 3,  'INFO': 1, 'CRITICAL': 4,  'BLOCKER': 5}
    refs = {}

    if not is_float(data.loc[0, 'severity']):
        frequencyClass = {}
        type = {'BUG': 2, 'VULNERABILITY': 3, 'CODE_SMELL': 1}

        for i in range(len(data)):
            if data.loc[i, 'component'] in frequencyClass.keys():
                if adjust_debt(data.loc[i, 'debt']) > 0:
                    frequencyClass[data.loc[i, 'component']] += 1
                    debts[data.loc[i, 'component']] += data.loc[i, 'debt']
                    severities[data.loc[i, 'component']] += severity[data.loc[i, 'severity']]
                    types[data.loc[i, 'component']] += type[data.loc[i, 'type']]
                    refs[data.loc[i, 'component']] = data.loc[i, 'Types']
            else:
                if adjust_debt(data.loc[i, 'debt']) > 0:
                    frequencyClass[data.loc[i, 'component']] = 1
                    debts[data.loc[i, 'component']] = data.loc[i, 'debt']
                    severities[data.loc[i, 'component']] = severity[data.loc[i, 'severity']]
                    types[data.loc[i, 'component']] = type[data.loc[i, 'type']]
                    refs[data.loc[i, 'component']] = data.loc[i, 'Types']

        for key in frequencyClass:
            severities[key] /= frequencyClass[key]
            debts[key] /= frequencyClass[key]
            types[key] /= frequencyClass[key]

        components = frequencyClass.keys()
        newData = {"component": components, "severity": severities.values(), "debt": debts.values(), "type": types.values(), "RTypes": refs.values()}
        df = pd.DataFrame(newData)
        return df
    else:
        newData = {"component": data['component'], "severity": data['severity'], "debt": data['debt'],
                   "type": data['type'], "RTypes": data['Types']}
        df = pd.period_range.DataFrame(newData)
        return df

df = adjust_excel_with_avg_mean(df)

df['RTypes'] = df['RTypes'].replace('[]', 'Empty_list')

excel_file_path = '/content/gdrive/MyDrive/maintainability/Refs/TuxGuitarRefactoringsAndTDOneRefOneComp.xlsx'
df.to_excel(excel_file_path, index=False)
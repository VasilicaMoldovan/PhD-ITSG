# -*- coding: utf-8 -*-
"""RefactoringMoment-RNNClassification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uUrkL7JpDBL0NVn94LuNQemgv-nvk-fd
"""

#RNN Classification

pip install imbalanced-learn

from keras.models import Sequential
from keras.layers import Dense, LSTM, Dropout, Embedding
import pandas as pd
from sklearn.model_selection import train_test_split
import numpy as np
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.preprocessing import sequence
import plotly.express as px
from sklearn.metrics import classification_report, accuracy_score, recall_score
from keras.utils import to_categorical
import matplotlib.pyplot as plt
from imblearn.over_sampling import SMOTE, RandomOverSampler
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline

from google.colab import drive
drive.mount('/content/gdrive')

df = pd.read_excel('/content/gdrive/MyDrive/maintainability/Refs/FreeMindRefactoringsAndTDRefAll.xlsx')
df.drop(columns=df.columns[0], axis=1,  inplace=True)

df['Types'].value_counts().plot(kind='bar', color='skyblue')
plt.title('Distribution of String Values')
plt.xlabel('String Values')
plt.ylabel('Frequency')
plt.show()

# Get value counts and create a DataFrame
value_counts_df = df['Types'].value_counts().reset_index()
value_counts_df.columns = ['String Values', 'Frequency']

# Display the table
print(value_counts_df)

le = LabelEncoder()
df['severity'] = le.fit_transform(df['severity'])
df['type'] = le.fit_transform(df['type'])
df['Types'] = le.fit_transform(df['Types'])

train, test = train_test_split(df, test_size=0.2)

features = df.columns[:-1]
X = train[features] # her we are droping the output feature as this is the target and 'X' is input features, the changes are not
                                # made inplace as we have not used 'inplace = True'
y = train['Types'] # Output/Dependent variable
XTest = test[features]
YTest = test['Types']

X = np.asarray(X).astype('float32')
y = np.asarray(y).astype('float32')

#norms = np.linalg.norm(X, axis=1, keepdims=True)
#X = X / norms
min_val = 0.0
max_val = 36.0

# Check if values are outside the interval and set them to 0.0
X[(X < min_val) | (X > max_val)] = 0.0

X = np.nan_to_num(X, nan=0.0)

sampling_strategy = {0: 1500, 1: 1500, 2: 1800}
over = SMOTE(sampling_strategy=sampling_strategy)
under = RandomUnderSampler(sampling_strategy=sampling_strategy)
steps = [('o', over), ('u', under)]
pipeline = Pipeline(steps=steps)
X, y = pipeline.fit_resample(X, y)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)

print(set(np.unique(X_test)))
print(set(np.unique(y_test)))

max_review_length = 3
X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)
X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)

y_train = to_categorical(y_train, num_classes=36)
y_test = to_categorical(y_test, num_classes=36)

# create the model
embedding_vecor_length = 50
model = Sequential()
model.add(Embedding(input_dim=100, output_dim=embedding_vecor_length, input_length=max_review_length))
model.add(LSTM(100))
model.add(Dense(36, activation='softmax'))  # Use softmax for multi-class classification
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
print(model.summary())
model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=64)

# Final evaluation of the model
scores = model.evaluate(X_test, y_test, verbose=0)
print("Accuracy: %.2f%%" % (scores[1]*100))

embedding_vector_features = 50
model = Sequential()
model.add(Embedding(len(X_train),embedding_vector_features,input_length=3))

model.add(LSTM(128,input_shape=(X_train.shape),activation='relu',return_sequences=True))

model.add(Dropout(0.2))

model.add(LSTM(128,activation='tanh'))

model.add(Dropout(0.2))
model.add(Dense(32,activation='relu'))

model.add(Dropout(0.2))

model.add(Dense(36,activation='softmax'))

model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

print(model.summary())

model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=50,batch_size=64)

results = model.evaluate(X_test,y_test)

predictions = model.predict(X_test)

predicted_labels = np.argmax(predictions, axis=1)
predicted_labels = to_categorical(predicted_labels, num_classes=36)
predicted_labels

object1_first_column = predictions[:, 0]
accuracy = accuracy_score(y_test, predicted_labels)
print(classification_report(y_test, predicted_labels))